{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBus0bRsCvAt"
      },
      "source": [
        "# 이름/학번\n",
        "\n",
        "이름:20171722\n",
        "\n",
        "학번:이장범"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwxh7w0SCvA1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnKIPUv2CvA4"
      },
      "source": [
        "# Example dataset\n",
        "\n",
        "강의를 위해서 임의의 dataset을 준비하겠습니다.\n",
        "예제로 봐주시고, 큰 물리적 의미는 부여하지 않겠습니다.\n",
        "\n",
        "- Data는 장미과와 국화과의 A 효소, B 효소, C 효소, D 효소를 측정한 값이라고 가정합니다.\n",
        "- Label은 각 sample이 장미인지 (0) 국화인지 (1)에 대한 정보라고 가정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHdbjzjMCvA5"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "num_feature = 4\n",
        "torch.manual_seed(0)\n",
        "\n",
        "X_batch = torch.randn(batch_size, num_feature)\n",
        "Y_batch = (torch.sum(X_batch, dim=1)>0).type(torch.float).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ybbfxKCvA7",
        "outputId": "00acb0c4-4f0c-4ef2-ccb7-4fc6396f9309"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
              "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
              "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
              "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
              "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
              "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
              "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
              "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
              "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
              "        [-0.5181, -0.3067, -1.5810,  1.7066]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRlbrrDsCvA8",
        "outputId": "92d9309c-043a-4838-d120-70eda38f17ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "Y_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BF97q0DCvA9"
      },
      "source": [
        "# Notation 정리\n",
        "\n",
        "강의자료와 비교하면 \n",
        "\n",
        "\\begin{align*}\n",
        "\\text{X_batch} = \n",
        "\\begin{bmatrix}\n",
        "(x^{(1)})^\\top\\\\\n",
        "(x^{(2)})^\\top\\\\\n",
        "\\vdots \\\\\n",
        "(x^{(m)})^\\top\n",
        "\\end{bmatrix}, \\quad\n",
        "\\text{Y_batch} = \n",
        "\\begin{bmatrix}\n",
        "y^{(1)}\\\\\n",
        "y^{(2)}\\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)}\n",
        "\\end{bmatrix}\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnwu79C2CvA_"
      },
      "source": [
        "# Example Problem: Single Neuron\n",
        "\n",
        "- 한개의 neuron이 있다고 가정하고 $\\mathbb{R}^4$ 를 입력받아서 $\\mathbb{R}$로 출력한다고 가정합니다.\n",
        "- Activation 함수는 ReLU 함수, 즉, \n",
        "\\begin{align*}\n",
        "\\text{ReLU}(x) = \\max(0, x)\n",
        "\\end{align*}\n",
        "를 사용한다고 가정합니다.\n",
        "\n",
        "Neuron을 통해서 batch sample 전체를\n",
        "\\begin{align*}\n",
        "Z = \\begin{bmatrix}\n",
        "(w^T x^{(1)} + b)^T \\\\\n",
        "(w^T x^{(2)} + b)^T \\\\\n",
        "\\vdots \\\\\n",
        "(w^T x^{(m)} + b)^T\n",
        "\\end{bmatrix} \n",
        "\\end{align*}\n",
        "연산을 수행해서 $Z$를 구하세요.\n",
        "\n",
        "- $w$는 random Gaussian으로 생성하세요. 위에서 예기한 입력과 출력이 맞도록 weight를 생성하세요.\n",
        "- Bias $b$는 1로 설정\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2G_2OntCvBB",
        "outputId": "1b45f55b-4d3a-40a1-9555-426edfec783c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6020],\n",
            "        [ 1.6919],\n",
            "        [-0.3206],\n",
            "        [-0.8471],\n",
            "        [-1.2320],\n",
            "        [ 1.5082],\n",
            "        [-0.6258],\n",
            "        [-1.3570],\n",
            "        [ 3.9385],\n",
            "        [ 4.6839]])\n"
          ]
        }
      ],
      "source": [
        "# 답 작성\n",
        "\n",
        "W = torch.randn(num_feature, 1)\n",
        "b = 1\n",
        "Z = torch.matmul(X_batch, W)+b\n",
        "print(Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmKgUwetCvBD"
      },
      "source": [
        "원하는 연산을 하는지 확인하도록 합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2KORRxmCvBE",
        "outputId": "74d7ed2e-f6ab-4afb-ea13-aa4673341aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6020],\n",
            "        [ 1.6919],\n",
            "        [-0.3206],\n",
            "        [-0.8471],\n",
            "        [-1.2320],\n",
            "        [ 1.5082],\n",
            "        [-0.6258],\n",
            "        [-1.3570],\n",
            "        [ 3.9385],\n",
            "        [ 4.6839]])\n"
          ]
        }
      ],
      "source": [
        "z_loop = torch.empty(batch_size, 1)\n",
        "for i in torch.arange(batch_size):\n",
        "    z_loop[i,:] = torch.matmul(W.T, X_batch[i,:].T)+b\n",
        "print(z_loop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMwVU5DBCvBF"
      },
      "source": [
        "## Problem 1\n",
        "ReLU 함수를 작성하고 위에서 찾은 $Z$의 각 원소에 ReLU 함수를 적용하여 `a`라는 변수에 저장하세요.\n",
        "\n",
        "- torch.clamp() 함수를 공부하고 적용하세요\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEuV0JHqCvBG",
        "outputId": "3b4f38f5-6dec-4815-edb3-cd857d227bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6020],\n",
            "        [1.6919],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [1.5082],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [3.9385],\n",
            "        [4.6839]])\n"
          ]
        }
      ],
      "source": [
        "# 답 작성:\n",
        "\n",
        "def ReLU(x):\n",
        "    a=torch.clamp(x,min=0)\n",
        "    return a\n",
        "\n",
        "A = ReLU(Z)\n",
        "\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPEDEdtGCvBH"
      },
      "source": [
        "# Single Layer Network\n",
        "\n",
        "- 한개의 Layer에 $k=5$개의 Neuron 이 있는 network를 구성하고 출력을 구하세요\n",
        "- Activation function은 모든 neuron에 ReLU를 적용합니다\n",
        "- 모든 weight는 Gaussian 분포로 랜덤 생성하세요 `torch.randn()`\n",
        "- $i$ 번째 neuron의 weight들을 $w_i$라고 할때,\n",
        "\\begin{align*}\n",
        "\\text{W} = \\begin{bmatrix}\n",
        "w_1, w_2, w_3, w_4, w_5\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "라고 하고, weight matrix `W`를 만드세요.\n",
        "  - `W = torch.randn(???, ???)` 으로 생성\n",
        "- Bias 역시 `b`라는 `tensor`에 저장하고, 각 neuron 별로 `1`로 설정합니다\n",
        "  - `b = torch.ones(???,???)`\n",
        "- 아래 problem 2-2에서 수업에서 배운 $Z$ 행렬과 $A$ 행렬을 구하세요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7_NPbZCvBI"
      },
      "source": [
        "# Problem 2-1\n",
        "`Z` 행렬과 `A` 행렬의 차원은 어떻게 나와야하나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDpyvuadCvBJ"
      },
      "source": [
        "답 작성)\n",
        "\n",
        "Z 는 (10,1), \n",
        "A 는 (10,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC0jQmpfCvBJ"
      },
      "source": [
        "# Problem 2-2 \n",
        "위에서 요구한 코딩을 완성하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zjwQaDiCvBK",
        "outputId": "95ef1e63-51d7-4900-a079-ada1283d84ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4628, 1.9304, 1.7424, 0.0000, 2.0341],\n",
            "        [1.8148, 2.8405, 0.7133, 3.1585, 0.0000],\n",
            "        [0.0000, 0.8103, 0.0000, 0.3271, 2.3345],\n",
            "        [0.0000, 1.9673, 2.2396, 5.1747, 0.3568],\n",
            "        [0.0000, 1.2024, 1.4051, 0.0000, 3.4587],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 2.7331],\n",
            "        [0.0000, 1.2425, 0.6161, 0.9942, 2.1074],\n",
            "        [0.0000, 1.2177, 0.6086, 1.7837, 2.3200],\n",
            "        [2.6548, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [4.7414, 0.0000, 0.9934, 0.0000, 1.2204]])\n"
          ]
        }
      ],
      "source": [
        "# 답 작성\n",
        "\n",
        "W = torch.randn(4,5)\n",
        "b = torch.ones(10,5) \n",
        "\n",
        "Z = torch.add(torch.matmul(X_batch,W),b)\n",
        "A = ReLU(Z)\n",
        "\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSMtImPwCvBL"
      },
      "source": [
        "# Problem 3: \n",
        "\n",
        "- $x^{(3)}$ 를 입력으로하는 2번째 Neuron의 결과값을 출력하세요\n",
        "- 위에서 구한 `A[i, j]`  인덱싱을 통해서 출력하세요\n",
        "- `Python`의 인덱싱은 `0`부터 시작한다는 것을 주의하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2rGRuw7CvBL",
        "outputId": "7a2f4351-e0ef-421f-8be0-007e85e35132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer =  tensor(1.1958)\n"
          ]
        }
      ],
      "source": [
        "# 답 작성\n",
        "\n",
        "print('answer = ', A[2, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm-GBO7gCvBM"
      },
      "source": [
        "# Problem 4: Multi-Layer network\n",
        "\n",
        "- 3개의 layer가 있는 network를 구성합니다.\n",
        "- 2번째 layer의 입력 크기는 $k^{[1]}=16$, 출력 크기는 $k^{[2]}=6$\n",
        "- 마지막 layer의 출력은 $k^{[3]}=1$개의 neuron으로 구성\n",
        "- 각 layer의 연산값을 구하세요. \n",
        "  - 각 layer의 선형 변환 결과값은 `Z1`, `Z2`, `Z3`로 저장하세요\n",
        "  - 각 layer의 결과값은 `A1`, `A2`, `A3`로 저장하세요\n",
        "- 모든 weight는 Gaussian 랜덤 변수로 생성, bias는 1로 구성된 벡터로 생성함\n",
        "- 각 layer의 weight는 `W1`, `W2`, `W3`로하고, bias는 `b1`, `b2`, `b3`로 생성함\n",
        "- Activation 함수는 `ReLU`를 적용하세요\n",
        "- Loop 없이 행렬연산으로 구생하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09EapayGCvBN"
      },
      "outputs": [],
      "source": [
        "# 답 작성\n",
        "#X_batch(4 x 10)\n",
        "W1= torch.randn(4,16)\n",
        "W2= torch.randn(16,6)\n",
        "W3= torch.randn(6,1)\n",
        "b1= torch.randn(10,16)\n",
        "b2= torch.randn(10,6)\n",
        "b3= torch.randn(10,1)\n",
        "\n",
        "Z1 = torch.add(torch.matmul(X_batch,W1),b1)\n",
        "A1 = ReLU(Z1)\n",
        "Z2 = torch.add(torch.matmul(A1,W2),b2)\n",
        "A2 = ReLU(Z2)\n",
        "Z3 = torch.add(torch.matmul(A2,W3),b3) \n",
        "A3= ReLU(Z3)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcG9MVj_CvBN",
        "outputId": "97456e7a-162f-4ce6-f08a-d0ff23bc2137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 16])\n",
            "tensor([[ 1.3965,  3.3318, -2.7778,  0.6777,  0.8293, -2.2252,  0.9632,  0.5943,\n",
            "          0.1613,  2.0459,  1.8352,  0.3523,  0.6498, -2.1673, -1.7040, -1.4087],\n",
            "        [-0.2542, -2.0121, -4.5212,  2.5301, -0.0613,  2.7345,  0.8815, -3.0281,\n",
            "          2.5351, -3.2095, -0.5035,  3.3415, -2.7684, -5.1268,  2.2618, -2.0164],\n",
            "        [-0.6609,  4.4134,  1.8273,  1.9412, -0.1793, -1.7065, -0.5464,  1.0321,\n",
            "         -0.4691,  4.0308,  2.3676, -0.2298,  2.2407,  2.4497, -2.9524, -2.0576],\n",
            "        [-1.1050, -2.3983,  1.2923, -0.4841, -1.3498,  2.1929, -1.7050,  0.6444,\n",
            "          1.0799, -2.0810, -0.8460,  1.0903, -2.5134, -3.6423,  2.0043,  0.1092],\n",
            "        [ 2.1356,  3.4715,  2.6039,  0.8777, -0.8044, -4.6825, -0.7029,  5.1988,\n",
            "         -3.0278,  4.4924,  2.4911, -2.3280,  2.1252,  2.1511, -2.7072,  1.3035],\n",
            "        [-0.0921,  2.4784,  2.6864,  0.9587, -0.9666, -1.2776, -2.3343,  1.8303,\n",
            "         -2.5769,  6.2104,  1.5944, -1.9319,  4.0570, 10.1131, -2.6189,  3.6802],\n",
            "        [ 0.4451,  1.1393,  1.6426,  1.5401, -2.7748, -2.4377, -0.3619,  2.4419,\n",
            "         -0.9478,  2.9302,  2.6443,  0.5022,  1.8641,  1.1970, -0.3099, -1.3413],\n",
            "        [ 2.5300,  2.1575,  2.5027,  1.2049, -0.5396, -3.7842, -1.0467,  3.2403,\n",
            "         -1.8701,  2.6378,  3.3899,  0.0176,  0.7043,  0.4905, -2.3455, -0.7723],\n",
            "        [ 0.0322, -3.3530, -1.7781, -2.8638,  0.4584,  0.5408,  1.1714, -4.7722,\n",
            "          0.9260,  0.2544, -2.4125,  0.6626,  1.0241,  1.1624,  0.1622,  1.7753],\n",
            "        [ 2.7336, -2.3304,  0.5238, -2.9357,  0.2857, -1.8176,  0.1465, -0.1304,\n",
            "         -2.8668,  2.6831, -2.8463, -3.6524,  1.3610,  6.6352, -1.6025,  3.1670]])\n"
          ]
        }
      ],
      "source": [
        "print(Z1.shape)\n",
        "print(Z1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GsboUOnCvBO",
        "outputId": "036465a8-8db7-4404-b893-ec0eecebe499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 6])\n",
            "tensor([[ 2.5190e+00,  1.3521e+01,  6.9098e+00,  3.7462e-01,  2.3835e+00,\n",
            "         -5.8937e+00],\n",
            "        [ 1.4348e+00, -7.2728e+00, -2.2811e+00, -4.8635e+00,  3.2190e-01,\n",
            "          9.2533e+00],\n",
            "        [ 6.1557e+00,  2.4807e+01,  9.8516e+00,  1.2058e+00, -5.3691e+00,\n",
            "         -7.2355e+00],\n",
            "        [-1.5967e-01, -5.2809e+00,  2.8553e+00, -1.9418e+00,  1.9732e+00,\n",
            "          7.8655e+00],\n",
            "        [ 6.9917e+00,  2.5972e+01,  9.5147e+00,  1.7095e-01, -7.0582e-01,\n",
            "         -2.8162e+00],\n",
            "        [ 1.4599e+01,  2.7318e+01,  8.5156e+00,  5.9336e+00, -1.5492e+01,\n",
            "         -1.8271e+01],\n",
            "        [ 2.2121e+00,  1.2457e+01,  5.4034e+00, -1.5416e+00, -2.2739e+00,\n",
            "          1.2736e+00],\n",
            "        [-7.3316e-01,  1.8628e+01,  4.0927e+00, -8.5138e-01,  2.8913e+00,\n",
            "          2.0664e+00],\n",
            "        [ 3.7081e+00, -3.1217e+00,  1.8452e+00, -7.3169e-01, -7.3654e-03,\n",
            "         -2.5304e+00],\n",
            "        [ 4.9717e+00,  9.0720e+00, -2.1711e+00,  4.9885e+00, -5.3305e+00,\n",
            "         -9.1542e+00]])\n"
          ]
        }
      ],
      "source": [
        "print(Z2.shape)\n",
        "print(Z2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkX2L7agCvBP",
        "outputId": "34738fe1-90c9-45b9-95d2-c1f62e864156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1])\n",
            "tensor([[ -0.3643],\n",
            "        [-11.4960],\n",
            "        [  3.5035],\n",
            "        [-14.9579],\n",
            "        [  0.1458],\n",
            "        [ 12.0582],\n",
            "        [ -4.1134],\n",
            "        [  6.0082],\n",
            "        [ -6.0862],\n",
            "        [ 16.5274]])\n"
          ]
        }
      ],
      "source": [
        "print(Z3.shape)\n",
        "print(Z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7PqjzWpCvBP"
      },
      "source": [
        "# Problem 5\n",
        "- 위에서 구한 `A3[i,j]`의 인덱싱을 통해서 $h_\\theta(x^{(3)})$ 을 출력하세요\n",
        "- 역시 `python`인덱싱은 `0` 부터 시작한다는 것을 주의하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wa0-FnrCvBQ"
      },
      "outputs": [],
      "source": [
        "# 답 작성\n",
        "\n",
        "# print('h_theta(x3) = ', A3[?,?])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txMpPw-tCvBQ"
      },
      "source": [
        "# Problem 6\n",
        "위에서 공부한 것을 함수로 만들어 보도록 하겠습니다.\n",
        "아래 한 layer의 선형 변환을 연산하는 class를 만들어 보도록 하죠.\n",
        "\n",
        "- Class는 `my_linear_layer()`\n",
        "  - `__init__(self, n_input, n_output)` 함수:\n",
        "    - `self.W` 변수 초기화: Weight 행렬 `self.W`를 램덤 Gaussian 생성 (차원에 맞는...)\n",
        "    - `self.b` 변수 초기화: bias 벡터 `self.b`를 모두 `1`인 벡터 생성 (차원에 맞는...)\n",
        "  - `forward(A)` 함수:\n",
        "    - 입력: `A`는 sample batch $X$ 또는 전 layer에서 들어오는 입력 batch $A^{[\\ell-1]}$을 입력하는 자리\n",
        "    - return 값\n",
        "      - `Z` 변수는 $A^{[\\ell-1]}$의 선형 변환 값, 즉 $Z^{[\\ell]}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wlirq13CvBR"
      },
      "outputs": [],
      "source": [
        "# 답 작성\n",
        "class my_linear_layer():\n",
        "    def __init__(self, n_input, n_output):\n",
        "        #self.W = \n",
        "        #self.b = \n",
        "    \n",
        "    def forward(self,A):\n",
        "        #Z = \n",
        "        return Z\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aSpObOSCvBR"
      },
      "source": [
        "답을 확인하기 위해서 `n_input=num_feature`과 `n_output = 5` 인 `my_linear_layer` instance 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIzpbYmKCvBR"
      },
      "outputs": [],
      "source": [
        "mll = my_linear_layer(num_feature, 5)\n",
        "mll.forward(X_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRpcMkwlCvBS"
      },
      "outputs": [],
      "source": [
        "print(mll.W)\n",
        "print(mll.b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVBGipfCvBS"
      },
      "source": [
        "# Building a Linear Layer with `torch.nn`\n",
        "위에서 수행한 작업을 `pytorch`에서는 `torch.nn.Linear`라는 명령어로 쉽게 구현할 수 있습니다.\n",
        "아래 예제를 보도록 하죠"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPEgi4HSCvBT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "#W = torch.randn(num_feature, 5)\n",
        "L1 = nn.Linear(num_feature, 5)\n",
        "Zll = L1(X_batch)\n",
        "Zll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F36Ev9NCvBT"
      },
      "outputs": [],
      "source": [
        "L1.weight = nn.Parameter(W.T)\n",
        "L1.bias.data.fill_(1.0)\n",
        "Zll2 = L1(X_batch)\n",
        "Zll2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRSLrVIOCvBU"
      },
      "outputs": [],
      "source": [
        "Z"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "problemset1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}