{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OCYzdeqG4-g"
      },
      "source": [
        "# Loading MNIST DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfETFtMoG4-x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukOOthovG4-z"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnsJccTrG4-0"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUuSLgozG4-1",
        "outputId": "ecd94272-a490-49f0-d4c0-712f76c4e6cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-cQftlxG4-3",
        "outputId": "7a7566a1-75ad-4866-b7eb-239b8bff93bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1317)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "torch.mean(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej-LzGHoG4-4",
        "outputId": "05f5b969-01cd-4934-e1fb-461a5f2d9fc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3090)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "torch.std(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx02uY8pG4-6"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.13), (0.3)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSpvKUjVG4-8"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxobt-qTG4-9"
      },
      "outputs": [],
      "source": [
        "Xsample = images.reshape(images.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot5Sl7-iG4--",
        "outputId": "aae81e7e-1f28-4ac0-8453-5d51ccd5220b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "Xsample.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u3EHlxwG4-_"
      },
      "source": [
        "### Problem 1: Constructing the network model\n",
        "\n",
        "`FNC` class를 정의하고 `model`을 생성하세요:\n",
        "\n",
        "- input layer\n",
        "  - number of input features를 hidden unit 128개로 선형변환 및 ReLU activation function\n",
        "- Hidden layer\n",
        "  - 128 hidden unit을 64개 hidden unit으로 선형변환 및 ReLU\n",
        "- Output layer\n",
        "  - 64개 hidden unit을 10개 class로 분류하기 위한 output layer\n",
        "  - 최종 layer의 activation은 없음 (linear layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "Bf48b4gAG4_A"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "class FCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 초기화 method\n",
        "        self.seq = nn.Sequential(OrderedDict([('layer1', nn.Linear(784, 128)),\n",
        "        # input data에 num_features는 100, batch_size 는 30, OrderedDict\n",
        "                      ('relu1', nn.ReLU(True)),# activation function을 relu로 사용,\n",
        "                      ('layer2', nn.Linear(128, 64)), # hidden layer에 neruon 개수 80이므로, nn.Linear의 2번째 parameter 값을 80으로 설정했다. \n",
        "                      ('relu2',nn.ReLU(True)),# activation function을 relu로 사용,\n",
        "                      ('layer3', nn.Linear(64, 10)) # hidden layer에 neruon 개수 50이므로, nn.Linear의 2번째 parameter 값을 50으로 설정했다. \n",
        "                                            ])\n",
        "        )\n",
        "        \n",
        "    def forward(self, x): # forward 함수 불러오기\n",
        "        return self.seq(x) # 위에서 만든 self.fc 입력으로 들어오는 x를 넣고, forward pass 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "roPp3bdRG4_B"
      },
      "outputs": [],
      "source": [
        "model = FCN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVbMXrRkG4_C"
      },
      "source": [
        "## Loss Functions in PyTorch\n",
        "\n",
        "* 다음 과정으로, Pytorch에서 loss를 어떻게 연산하는지 배워보죠\n",
        "* `nn` module에서 다양한 loss function을 제공하는데, 예를 들면 `nn.CrossEntropyLoss`와 같은 함수가 있습니다\n",
        "    * 보통 관습적으로 loss function은 `critertion`이라는 변수로 받습니다 (`loss_function`등도 당연히 사용 가능합니다)\n",
        "* 지난 시간에 MNIST 문제는 확률 분포를 output으로 받는 것이 필요하다고 (또는 자연스러운 선택 임을) 학습했습니다 \n",
        "* 이런 확률 분포를 output으로 받는 경우 대응되는 좋은 loss function이 cross entropy입니다 (이론 강의에서 cross entropy가 무엇을 의미하는지 설명한 부분을 복습 해보세요)\n",
        "\n",
        "* Cross entropy의 정의는 \n",
        "\\begin{align*}\n",
        " J(\\theta) &=-\\frac{1}{m}\\sum_{i=1}^m P(y^{(i)}|x^{(i)})\\log(Q(y^{(i)}|x^{(i)}))\n",
        "\\end{align*}\n",
        "* 위 식은 두 확률 분포의 \"거리\"를 표현하는 식이라고 배웠습니다\n",
        "* 위에서 $P(y|x)$는 $y$의 label을 one hot coding 한 vector이고 $Q(y|x)$는 softmax를 취한 network output입니다\n",
        "* One hot coding은 label이 1이면 첫번째 자리만 '1'이고 나머지는 영인 벡터, label이 $k$이면 $k$ 번째 자리만 '1'이고 나머지는 0인 벡터입니다\n",
        "\n",
        "* 예를들어서 label이 2에 대한 one hot encoding\n",
        "\\begin{align*}\n",
        "y_\\textrm{one_hot}(2) &= \\begin{array}{cccccc}\n",
        "[0 & 0 & 1 & \\cdots & 0]\n",
        "\\end{array}\n",
        "\\end{align*}\n",
        "\n",
        "* 위 cross entropy 식에 대응 하는 방식은, label이 2라고 가정했을 때 분포는:\n",
        "\\begin{align*}\n",
        "P(y|x) = y_\\textrm{one_hot}(2), \\quad P(2|x) = (y_\\textrm{one_hot}(2))_2\n",
        "\\end{align*}\n",
        "\n",
        "* 또한, neural network의 마지막 linear layer의 output 값이 $z$라고 할때,\n",
        "\\begin{align*}\n",
        "Q(y=2|x) = \\sigma(z_2) = \\cfrac{\\exp(z_2)}{\\sum_k^K{\\exp(z_k)}}\n",
        "\\end{align*}\n",
        "\n",
        "![Classnote](https://drive.google.com/uc?export=download&id=17hcl4RJne65Vd17gKM8XKUTjYlqyFIY5)\n",
        "\n",
        "* pytorch에서 이를 수행하기 위해서 criterion을 `nn.CrossEntropyLoss`로 생성하고, network의 예측 값과, 실제 label 값을 입력으로 loss를 계산합니다\n",
        "  * 본 과정은 차근차근 설명하겠습니다\n",
        "* 그 전에 Pytorch에서 cross entropy 함수를 어떻게 적용하는지 먼저 이해할 필요가 있습니다 (중요합니다!!!)\n",
        "  * [Pytorch.org `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)를 살펴보면\n",
        "\n",
        "> This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
        ">\n",
        "> The input is expected to contain scores for each class.\n",
        "\n",
        "* `nn.CrossEntropyLoss`는 `nn.LogSoftmax()`와 `nn.NLLLoss()` 하나의 class에서 수행한다고 되어 있습니다. \n",
        "* 두번째 줄에서 NLLLoss 는 negative log likelihood loss 입니다 \n",
        "\n",
        "* 이게 의미하는 바가 무엇이냐면, network의 output을 softmax function을 적용하여 출력하지 말고, softmax는 loss function에서 계산한다는 뜻입니다\n",
        "* 이렇게 구현한 이유는, 확률값이 작을 수 있어서 computation precision error를 방지하기 위해서 그냥 raw output 값을 받고, loss function에서 log(prob) 형태로 연산하도록 모듈을 구성하였습니다\n",
        "\n",
        "* 아래 코드를 보면 조금 더 이해가 될 것이라고 생각합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JMHgg_eG4_E",
        "outputId": "fca1321c-a587-4dc5-ecf8-ac93d1bcfebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 784])\n",
            "tensor(2.2862, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.reshape(images.shape[0], -1)\n",
        "print(images.shape)\n",
        "# Forward pass, get our log-probabilities\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logps and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6O9VJpG4_G"
      },
      "source": [
        "\n",
        "### Problem 2: Implement softmax\n",
        "\n",
        "다음 `softmax` 함수를 만드세요\n",
        "\n",
        "- `softmax(x)`\n",
        "- `input`: (batchsize, num_class)의 최종 linear layer output\n",
        "- `output`: `softmax` 취한 output이 (batchsize, softmaxoutput) 차원으로 정렬\n",
        "\n",
        "- 유용할 수 있는 함수:\n",
        "    - `torch.sum`\n",
        "    - `torch.exp`\n",
        "    - broadcasting 사용 (reshape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T7pzCTIG4_H",
        "outputId": "f0ef1dbe-be4e-4047-c41d-2d6d9f87b984"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ],
      "source": [
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "R8eghyRjG4_I"
      },
      "outputs": [],
      "source": [
        "# 답작성\n",
        "def softmax(x):\n",
        "    h= torch.exp(x)/torch.sum(torch.exp(x),axis=1).reshape(-1,1)\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF_qGfmQG4_I",
        "outputId": "194e1b0f-e6f5-4c2f-b1da-ceaf03c592f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0952, 0.0929, 0.0881, 0.1156, 0.0947, 0.0826, 0.0839, 0.1114, 0.1074,\n",
              "         0.1283],\n",
              "        [0.0875, 0.0916, 0.1048, 0.1158, 0.0918, 0.0841, 0.0821, 0.1216, 0.0998,\n",
              "         0.1209],\n",
              "        [0.0843, 0.0950, 0.1150, 0.1013, 0.0911, 0.0821, 0.0859, 0.1322, 0.1032,\n",
              "         0.1100],\n",
              "        [0.0921, 0.0949, 0.0993, 0.1137, 0.1006, 0.0781, 0.0843, 0.1192, 0.0994,\n",
              "         0.1186],\n",
              "        [0.0959, 0.0820, 0.1033, 0.1125, 0.0857, 0.0817, 0.0721, 0.1292, 0.1097,\n",
              "         0.1280],\n",
              "        [0.0880, 0.1089, 0.0968, 0.1195, 0.0894, 0.0785, 0.0814, 0.1231, 0.1001,\n",
              "         0.1142],\n",
              "        [0.0997, 0.0943, 0.1024, 0.1314, 0.0817, 0.0775, 0.0783, 0.1096, 0.1048,\n",
              "         0.1203],\n",
              "        [0.0844, 0.0916, 0.1090, 0.1040, 0.0963, 0.0840, 0.0833, 0.1239, 0.1026,\n",
              "         0.1208],\n",
              "        [0.0891, 0.1005, 0.1049, 0.1222, 0.1012, 0.0796, 0.0826, 0.1191, 0.0919,\n",
              "         0.1090],\n",
              "        [0.0875, 0.0940, 0.0868, 0.1163, 0.0834, 0.0859, 0.0834, 0.1200, 0.1142,\n",
              "         0.1284],\n",
              "        [0.1031, 0.0902, 0.1017, 0.1344, 0.0854, 0.0795, 0.0750, 0.1123, 0.1051,\n",
              "         0.1134],\n",
              "        [0.0983, 0.0988, 0.1003, 0.1112, 0.0853, 0.0786, 0.0855, 0.1167, 0.1070,\n",
              "         0.1183],\n",
              "        [0.0996, 0.0998, 0.1003, 0.1222, 0.0838, 0.0707, 0.0839, 0.1055, 0.1093,\n",
              "         0.1250],\n",
              "        [0.0882, 0.1001, 0.1012, 0.1103, 0.0896, 0.0928, 0.0845, 0.1142, 0.1034,\n",
              "         0.1156],\n",
              "        [0.0966, 0.0927, 0.1006, 0.1053, 0.0986, 0.0798, 0.0886, 0.1198, 0.1019,\n",
              "         0.1161],\n",
              "        [0.0955, 0.0953, 0.1085, 0.1052, 0.0895, 0.0773, 0.0848, 0.1325, 0.0982,\n",
              "         0.1131],\n",
              "        [0.0825, 0.1143, 0.0972, 0.1109, 0.0918, 0.0861, 0.0863, 0.1209, 0.1003,\n",
              "         0.1096],\n",
              "        [0.0958, 0.0992, 0.1010, 0.1262, 0.0907, 0.0773, 0.0756, 0.1192, 0.0906,\n",
              "         0.1243],\n",
              "        [0.0933, 0.1035, 0.0944, 0.1231, 0.1008, 0.0765, 0.0783, 0.1167, 0.0957,\n",
              "         0.1176],\n",
              "        [0.0816, 0.1040, 0.1142, 0.1094, 0.0860, 0.0798, 0.0837, 0.1348, 0.1003,\n",
              "         0.1062],\n",
              "        [0.0910, 0.1063, 0.1097, 0.1064, 0.0921, 0.0864, 0.0846, 0.1124, 0.1040,\n",
              "         0.1071],\n",
              "        [0.0949, 0.0872, 0.1072, 0.1237, 0.0943, 0.0811, 0.0793, 0.1192, 0.0892,\n",
              "         0.1238],\n",
              "        [0.0948, 0.0951, 0.1034, 0.1219, 0.0844, 0.0772, 0.0802, 0.1169, 0.1040,\n",
              "         0.1221],\n",
              "        [0.0939, 0.0964, 0.0986, 0.1167, 0.0881, 0.0809, 0.0827, 0.1170, 0.1028,\n",
              "         0.1230],\n",
              "        [0.0887, 0.1077, 0.1092, 0.1044, 0.0768, 0.0793, 0.0862, 0.1277, 0.1101,\n",
              "         0.1100],\n",
              "        [0.0902, 0.1048, 0.0975, 0.1185, 0.0796, 0.0828, 0.0873, 0.1158, 0.1126,\n",
              "         0.1109],\n",
              "        [0.0924, 0.0950, 0.1040, 0.1229, 0.0912, 0.0885, 0.0821, 0.1033, 0.1037,\n",
              "         0.1169],\n",
              "        [0.0882, 0.0920, 0.1116, 0.1158, 0.0914, 0.0844, 0.0819, 0.1265, 0.0943,\n",
              "         0.1139],\n",
              "        [0.0960, 0.0921, 0.1038, 0.1144, 0.0906, 0.0885, 0.0779, 0.1197, 0.1038,\n",
              "         0.1132],\n",
              "        [0.0908, 0.0945, 0.1025, 0.1174, 0.0968, 0.0826, 0.0819, 0.1281, 0.0890,\n",
              "         0.1164],\n",
              "        [0.0860, 0.0943, 0.1079, 0.1204, 0.0871, 0.0852, 0.0826, 0.1218, 0.0987,\n",
              "         0.1159],\n",
              "        [0.0938, 0.1006, 0.0899, 0.1126, 0.0880, 0.0945, 0.0868, 0.1171, 0.1060,\n",
              "         0.1108],\n",
              "        [0.0835, 0.0908, 0.1047, 0.0972, 0.0997, 0.0809, 0.0824, 0.1317, 0.1033,\n",
              "         0.1260],\n",
              "        [0.0939, 0.0947, 0.1064, 0.1154, 0.0826, 0.0872, 0.0814, 0.1150, 0.1084,\n",
              "         0.1151],\n",
              "        [0.0854, 0.0938, 0.1047, 0.1161, 0.0886, 0.0822, 0.0839, 0.1263, 0.1009,\n",
              "         0.1181],\n",
              "        [0.0949, 0.1028, 0.0919, 0.1157, 0.0982, 0.0807, 0.0805, 0.1204, 0.0994,\n",
              "         0.1154],\n",
              "        [0.0864, 0.0900, 0.1073, 0.1138, 0.0908, 0.0851, 0.0858, 0.1234, 0.1054,\n",
              "         0.1121],\n",
              "        [0.0955, 0.0996, 0.1059, 0.1190, 0.0896, 0.0789, 0.0871, 0.1129, 0.0936,\n",
              "         0.1179],\n",
              "        [0.0921, 0.1033, 0.0991, 0.1237, 0.0860, 0.0804, 0.0803, 0.1084, 0.1068,\n",
              "         0.1200],\n",
              "        [0.0998, 0.0910, 0.0993, 0.1245, 0.0883, 0.0800, 0.0803, 0.1210, 0.1006,\n",
              "         0.1152],\n",
              "        [0.0812, 0.1124, 0.1045, 0.1057, 0.0849, 0.0815, 0.0953, 0.1160, 0.1096,\n",
              "         0.1086],\n",
              "        [0.0970, 0.0973, 0.1062, 0.1197, 0.0883, 0.0791, 0.0804, 0.1172, 0.0961,\n",
              "         0.1189],\n",
              "        [0.0855, 0.1056, 0.0992, 0.1179, 0.0877, 0.0818, 0.0915, 0.1094, 0.1091,\n",
              "         0.1124],\n",
              "        [0.0949, 0.0871, 0.1112, 0.1115, 0.0917, 0.0835, 0.0841, 0.1201, 0.0983,\n",
              "         0.1176],\n",
              "        [0.0904, 0.1087, 0.1157, 0.1208, 0.0804, 0.0766, 0.0755, 0.1216, 0.0959,\n",
              "         0.1145],\n",
              "        [0.0849, 0.1034, 0.0962, 0.1161, 0.0941, 0.0840, 0.0888, 0.1198, 0.0968,\n",
              "         0.1159],\n",
              "        [0.0944, 0.0868, 0.1051, 0.1144, 0.0844, 0.0794, 0.0834, 0.1206, 0.1111,\n",
              "         0.1204],\n",
              "        [0.0906, 0.0929, 0.1112, 0.1110, 0.0903, 0.0847, 0.0826, 0.1288, 0.0947,\n",
              "         0.1133],\n",
              "        [0.0943, 0.0904, 0.1069, 0.1242, 0.0868, 0.0858, 0.0822, 0.1164, 0.0947,\n",
              "         0.1183],\n",
              "        [0.0976, 0.0891, 0.1050, 0.1101, 0.0881, 0.0822, 0.0851, 0.1161, 0.1039,\n",
              "         0.1228],\n",
              "        [0.0853, 0.0885, 0.1067, 0.1147, 0.0941, 0.0790, 0.0806, 0.1254, 0.1093,\n",
              "         0.1163],\n",
              "        [0.0917, 0.1002, 0.0973, 0.1229, 0.0918, 0.0842, 0.0768, 0.1175, 0.1011,\n",
              "         0.1166],\n",
              "        [0.0928, 0.1141, 0.0926, 0.1197, 0.0876, 0.0846, 0.0825, 0.1111, 0.1006,\n",
              "         0.1146],\n",
              "        [0.0940, 0.0938, 0.1053, 0.1165, 0.0956, 0.0825, 0.0924, 0.1083, 0.1018,\n",
              "         0.1099],\n",
              "        [0.0909, 0.0918, 0.0951, 0.1106, 0.0869, 0.0818, 0.0892, 0.1148, 0.1128,\n",
              "         0.1262],\n",
              "        [0.0866, 0.0964, 0.1132, 0.1049, 0.0880, 0.0813, 0.0845, 0.1283, 0.1056,\n",
              "         0.1113],\n",
              "        [0.0951, 0.0883, 0.1060, 0.1205, 0.0866, 0.0786, 0.0800, 0.1203, 0.1026,\n",
              "         0.1220],\n",
              "        [0.0900, 0.0980, 0.1056, 0.1177, 0.0812, 0.0854, 0.0802, 0.1133, 0.1106,\n",
              "         0.1180],\n",
              "        [0.1137, 0.0791, 0.1126, 0.1230, 0.0903, 0.0775, 0.0800, 0.1120, 0.0891,\n",
              "         0.1228],\n",
              "        [0.0892, 0.0988, 0.0878, 0.1209, 0.0939, 0.0892, 0.0900, 0.1158, 0.1088,\n",
              "         0.1055],\n",
              "        [0.0895, 0.1009, 0.1020, 0.1054, 0.1054, 0.0792, 0.0884, 0.1210, 0.0954,\n",
              "         0.1128],\n",
              "        [0.0974, 0.1001, 0.1001, 0.1239, 0.0868, 0.0778, 0.0782, 0.1176, 0.1015,\n",
              "         0.1166],\n",
              "        [0.0838, 0.1005, 0.1097, 0.1072, 0.0946, 0.0792, 0.0781, 0.1320, 0.0973,\n",
              "         0.1177],\n",
              "        [0.0978, 0.1004, 0.1083, 0.1156, 0.0808, 0.0931, 0.0946, 0.1035, 0.1064,\n",
              "         0.0994]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ],
      "source": [
        "ps = softmax(logits)\n",
        "ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1qAk_PdG4_J"
      },
      "source": [
        "### Problem 3: Finding the Highest probability index\n",
        "\n",
        "Sample별 예측 확률값을 통하여 가장 높은 확률 값 예측 받는 함수를 작성하세요.\n",
        "\n",
        "`get_pred(ps)`\n",
        "- `input`: sample 별 확률값을 (batchsize, class probabilities) 로 받음\n",
        "- `output`: sample 별로 가장 높은 확률값의 index를 return\n",
        "\n",
        "- 유용할 수 있는 함수\n",
        "  - `torch.argmax`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "e5R8NZBCG4_K"
      },
      "outputs": [],
      "source": [
        "def get_pred(ps):\n",
        "    index = torch.argmax(ps,dim=1)\n",
        "    return index    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= get_pred(ps)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNnQuurPRu0C",
        "outputId": "749e016c-1da5-4d92-c727-f48d539bcef3"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 7, 7, 7, 7, 7, 3, 7, 3, 9, 3, 9, 9, 9, 7, 7, 7, 3, 3, 7, 7, 9, 9, 9,\n",
            "        7, 3, 3, 7, 7, 7, 7, 7, 7, 3, 7, 7, 7, 3, 3, 3, 7, 3, 3, 7, 7, 7, 7, 7,\n",
            "        3, 9, 7, 3, 3, 3, 9, 7, 9, 9, 3, 3, 7, 3, 7, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "653fe9dRG4_K"
      },
      "source": [
        "# Calculating Gradients"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.seq[0].weight.grad"
      ],
      "metadata": {
        "id": "Wck_s1CmTxs6"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ4bkWD7G4_L",
        "outputId": "e85687b7-dc4f-4c8d-c29c-a714fd05af79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 2.5222e-04,  2.5222e-04,  2.5222e-04,  ...,  2.5222e-04,\n",
            "          2.5222e-04,  2.5222e-04],\n",
            "        [ 1.6377e-04,  1.6377e-04,  1.6377e-04,  ...,  1.6377e-04,\n",
            "          1.6377e-04,  1.6377e-04],\n",
            "        [ 1.7321e-04,  1.7321e-04,  1.7321e-04,  ...,  1.7321e-04,\n",
            "          1.7321e-04,  1.7321e-04],\n",
            "        ...,\n",
            "        [ 2.4551e-04,  2.4551e-04,  2.4551e-04,  ...,  2.4551e-04,\n",
            "          2.4551e-04,  2.4551e-04],\n",
            "        [-5.6199e-05, -5.6199e-05, -5.6199e-05,  ..., -5.6199e-05,\n",
            "         -5.6199e-05, -5.6199e-05],\n",
            "        [ 7.2787e-04,  7.2787e-04,  7.2787e-04,  ...,  7.2787e-04,\n",
            "          7.2787e-04,  7.2787e-04]])\n"
          ]
        }
      ],
      "source": [
        "print('Before backward pass: \\n', model.seq[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model.seq[0].weight.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qql7f116G4_M"
      },
      "source": [
        "## Training the network!\n",
        "\n",
        "\n",
        "* 자, 그럼 network parameter에 대한 loss function의 gradient를 구했으니, 이제 최적화를 할 수 있습니다\n",
        "* 최적화 기법은 SGD 이외에도 많으며 (SGD의 변형들임) [`optim` package](https://pytorch.org/docs/stable/optim.html)에서 찾아서 사용할 수 있습니다\n",
        "* 예를 들어서 SGD는 `optim.SGD`를 통해서 불러올 수 있습니다\n",
        "* 아래 예를 보죠"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "wxntzoDIG4_N"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n-Qsfj_G4_N"
      },
      "source": [
        "* model.parameters()는 우리 network의 모든 training parameter이며, lr는 learning rate 입니다\n",
        "* 자, 이제 traning에 필요한 모든 부분이 준비되었습니다\n",
        "* 전체 데이터에 대한 training은 숙제로 하고, 한 batch만 수행하는 과정을 살펴보죠\n",
        "* Pytorch에서 training의 전체 흐름은 다음과 같습니다:\n",
        "\n",
        "1. Network에서 forward pass\n",
        "2. Foward pass를 통해서 얻은 output을 활용하여 loss를 구한다\n",
        "3. Gradient를 구하기 위해서 `loss.backward()`를 실행한다\n",
        "4. Optimizer에서 weight를 한번 update 한다 (SGD의 경우 gradient에 대해서 한번 update)\n",
        "\n",
        "**[중요]**\n",
        "* 한가지 주의할 점은, 한 Parameter들에 대해서 gradient를 여러개 구해야하는 경우, (예, batch 처리) gradient 값들은 계속 추가적으로 저장됩니다\n",
        "* 한번 parameter update가 끝났으면, gradient 값을 초기화해야, 새로운 batch에 대한 새 gradient 값을 계산 합니다\n",
        "* 이를 위해서 batch 시작시에 `optimizer.zero_grad()`를 실행해줘야합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "F0BE9PyNG4_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b705c3c-26b1-44f8-d9d9-71552e8be263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0077,  0.0020,  0.0014,  ..., -0.0189,  0.0049,  0.0342],\n",
            "        [-0.0174,  0.0095,  0.0216,  ...,  0.0143,  0.0138, -0.0185],\n",
            "        [ 0.0357, -0.0064,  0.0311,  ..., -0.0095,  0.0181, -0.0112],\n",
            "        ...,\n",
            "        [-0.0143,  0.0069,  0.0130,  ..., -0.0039, -0.0242,  0.0202],\n",
            "        [ 0.0334, -0.0074,  0.0016,  ..., -0.0086, -0.0069,  0.0331],\n",
            "        [ 0.0246,  0.0276,  0.0088,  ..., -0.0325, -0.0311,  0.0078]],\n",
            "       requires_grad=True)\n",
            "Gradient - Parameter containing:\n",
            "tensor([[ 0.0077,  0.0020,  0.0014,  ..., -0.0189,  0.0049,  0.0342],\n",
            "        [-0.0172,  0.0097,  0.0218,  ...,  0.0145,  0.0139, -0.0184],\n",
            "        [ 0.0357, -0.0064,  0.0311,  ..., -0.0095,  0.0181, -0.0112],\n",
            "        ...,\n",
            "        [-0.0142,  0.0070,  0.0131,  ..., -0.0038, -0.0241,  0.0203],\n",
            "        [ 0.0334, -0.0074,  0.0016,  ..., -0.0087, -0.0069,  0.0330],\n",
            "        [ 0.0246,  0.0277,  0.0088,  ..., -0.0325, -0.0311,  0.0079]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print('Initial weights - ', model.seq[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "\n",
        "print('Gradient -', model.seq[0].weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxsipqMfG4_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d684005-598a-4a3c-a132-781849fa0c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ Starting epoch: 0 --------\n",
            "Training loss: 0.7488392205285365\n",
            "Training acc: 0.8098847270011902\n",
            "------ Starting epoch: 1 --------\n",
            "Training loss: 0.3125993875043987\n",
            "Training acc: 0.9097814559936523\n",
            "------ Starting epoch: 2 --------\n",
            "Training loss: 0.2596812234250213\n",
            "Training acc: 0.9244902729988098\n",
            "------ Starting epoch: 3 --------\n",
            "Training loss: 0.22363737432448977\n",
            "Training acc: 0.9355177283287048\n",
            "------ Starting epoch: 4 --------\n",
            "Training loss: 0.1954114610976629\n",
            "Training acc: 0.943496823310852\n",
            "------ Starting epoch: 5 --------\n",
            "Training loss: 0.1728574597119872\n",
            "Training acc: 0.9508428573608398\n",
            "------ Starting epoch: 6 --------\n",
            "Training loss: 0.15415465394094555\n",
            "Training acc: 0.9555570483207703\n",
            "------ Starting epoch: 7 --------\n",
            "Training loss: 0.1392689456484084\n",
            "Training acc: 0.9602711796760559\n",
            "------ Starting epoch: 8 --------\n",
            "Training loss: 0.1264999778980989\n",
            "Training acc: 0.9643190503120422\n",
            "------ Starting epoch: 9 --------\n",
            "Training loss: 0.1160673670141078\n",
            "Training acc: 0.9667677283287048\n",
            "------ Starting epoch: 10 --------\n",
            "Training loss: 0.10627490832114905\n",
            "Training acc: 0.9697494506835938\n",
            "------ Starting epoch: 11 --------\n",
            "Training loss: 0.09831999467292638\n",
            "Training acc: 0.9723647236824036\n",
            "------ Starting epoch: 12 --------\n",
            "Training loss: 0.09092016411381268\n",
            "Training acc: 0.9747801423072815\n",
            "------ Starting epoch: 13 --------\n",
            "Training loss: 0.08450974787134669\n",
            "Training acc: 0.9763292670249939\n",
            "------ Starting epoch: 14 --------\n",
            "Training loss: 0.07899852734166327\n",
            "Training acc: 0.9777951836585999\n",
            "------ Starting epoch: 15 --------\n",
            "Training loss: 0.07380020930203421\n",
            "Training acc: 0.9792777299880981\n",
            "------ Starting epoch: 16 --------\n",
            "Training loss: 0.06903391517202324\n",
            "Training acc: 0.9808768630027771\n",
            "------ Starting epoch: 17 --------\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 100\n",
        "loss_epoch = []\n",
        "acc_epoch = []\n",
        "\n",
        "for e in range(epochs):\n",
        "    print(f\"------ Starting epoch: {e} --------\")\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        images = images.reshape(images.shape[0], -1)\n",
        "    \n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        ps = softmax(logits)\n",
        "        pred = get_pred(ps)\n",
        "        running_acc += torch.sum(pred==labels)/labels.shape[0] \n",
        "        \n",
        "               \n",
        "    acc_epoch.append(running_acc/len(trainloader))    \n",
        "    loss_epoch.append(running_loss/len(trainloader))\n",
        "    print(f\"Training loss: {loss_epoch[e]}\")\n",
        "    print(f\"Training acc: {acc_epoch[e]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwS3LgVPG4_P"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), loss_epoch)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Xm38EikG4_Q"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(epochs), acc_epoch)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BB3Up_gG4_Q"
      },
      "outputs": [],
      "source": [
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k56sJ-b6G4_R"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = softmax(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3mzfgsrG4_R"
      },
      "outputs": [],
      "source": [
        "labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p3DzpBoNnI99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7klrSBfCG4_S"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "problemset3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}